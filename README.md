```markdown
# ğŸ§˜ GuruGPT â€“ Chatbot IA com Streamlit + Ollama

GuruGPT Ã© um **chatbot multilinhas anÃ´nimo** com interface em Streamlit, integraÃ§Ã£o com modelos locais via **Ollama** e suporte a **anÃ¡lise de PDFs** usando PyMuPDF.  
O foco Ã© oferecer uma experiÃªncia de chat â€œzenâ€, com mÃºltiplas conversas, histÃ³rico e contexto de documentos.

---

## âœ¨ Features

- ğŸ’¬ Chat em mÃºltiplas conversas (multiâ€‘sessions) com histÃ³rico por sessÃ£o.
- ğŸ§  IntegraÃ§Ã£o com **Ollama** para uso de modelos LLM locais.
- ğŸ“„ Upload e leitura de **PDFs** com extraÃ§Ã£o de texto via PyMuPDF.
- ğŸ•¶ï¸ Tema escuro customizado e layout wide em Streamlit.
- ğŸ§¾ Controle de estado via `st.session_state` (ID anÃ´nimo, conversas, PDF em uso).
- ğŸ§± Sidebar com:
  - Lista de conversas
  - SeleÃ§Ã£o de modelo Ollama
  - Identificador anÃ´nimo da sessÃ£o

---

## ğŸ§© Arquitetura do Projeto

Principais tecnologias:

- [Streamlit](https://streamlit.io/) â€“ UI web.
- [Ollama](https://ollama.com/) â€“ Modelos LLM locais.
- [PyMuPDF (fitz)](https://pymupdf.readthedocs.io/) â€“ Leitura e extraÃ§Ã£o de texto de PDFs.
- Python 3.12+ (recomendado em venv).

### Estrutura bÃ¡sica

```text
.
â”œâ”€â”€ app.py            # App Streamlit principal
â”œâ”€â”€ requirements.txt  # DependÃªncias de Python
â””â”€â”€ (outros arquivos e configs)
```


### Principais componentes do `app.py`

- `get_ollama_models()`
Lista os modelos instalados localmente no Ollama e exibe no seletor da sidebar.
- `stream_ollama_response(model, messages)`
Faz streaming da resposta do Ollama, chunk a chunk, para o chat do usuÃ¡rio.
- `extract_pdf_text(file_bytes)`
LÃª um PDF enviado pelo usuÃ¡rio e extrai todo o texto usando PyMuPDF.
- `init_state()` / `_new_conv()` / `current_messages()`
Gerenciam o estado da sessÃ£o: ID anÃ´nimo, conversas, conversa ativa e contexto de PDF.
- `render_sidebar(models)`
Monta a sidebar com:
    - Logo / branding
    - Lista de conversas
    - SeleÃ§Ã£o de modelo Ollama
    - Info da sessÃ£o anÃ´nima
- `render_logo(models)`
Renderiza o logo â€œGuruGPTâ€ e mensagens de status na tela principal.

---

## ğŸ“¦ DependÃªncias

Do arquivo `requirements.txt`:

```txt
streamlit>=1.32.0
ollama>=0.1.8
PyMuPDF>=1.23.0
```


---

## ğŸš€ Como rodar localmente (Linux)

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/SEU_USUARIO/gurugpt.git
cd gurugpt
```


### 2. Criar e ativar o ambiente virtual

```bash
python3 -m venv .venv
source .venv/bin/activate
```

> âš ï¸ Isso evita o erro `externally-managed-environment` do pip (PEP 668) ao instalar pacotes no Python do sistema.

### 3. Instalar dependÃªncias

```bash
pip install -r requirements.txt
```


### 4. Instalar e configurar o Ollama

- Instale o Ollama no seu sistema (veja docs oficiais: https://ollama.com).
- Puxe pelo menos um modelo (por exemplo, `llama3`):

```bash
ollama pull llama3
```

- Certifique-se de que o serviÃ§o do Ollama estÃ¡ rodando antes de iniciar o GuruGPT.


### 5. Rodar o app Streamlit

Por padrÃ£o, o Streamlit roda na porta `8501`:

```bash
streamlit run app.py
```

Abra no navegador:

```text
http://localhost:8501
```


### 6. Escolher outra porta (opcional)

```bash
streamlit run app.py --server.port=8502
```

Ou configure no arquivo `.streamlit/config.toml`:

```toml
[server]
port = 8502
```


---

## ğŸŒ Deploy com NGINX (reverse proxy)

Abaixo um exemplo de como publicar o GuruGPT na web usando **NGINX como proxy reverso**.

### 1. Rodar o Streamlit em background

Exemplo rodando na porta `8501`:

```bash
cd /var/www/gurugpt.com.br
source .venv/bin/activate
streamlit run app.py --server.port=8501
```

VocÃª pode usar `tmux`, `screen` ou um serviÃ§o `systemd` para manter o processo rodando.

### 2. Configurar o NGINX

Crie um arquivo de site, por exemplo:

```bash
sudo nano /etc/nginx/sites-available/gurugpt.com.br
```

Com o conteÃºdo:

```nginx
server {
    listen 80;
    server_name gurugpt.com.br www.gurugpt.com.br;

    location / {
        proxy_pass http://127.0.0.1:8501;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;

        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
}
```


### 3. Habilitar o site e recarregar o NGINX

```bash
sudo ln -s /etc/nginx/sites-available/gurugpt.com.br /etc/nginx/sites-enabled/gurugpt.com.br

sudo nginx -t      # testa a configuraÃ§Ã£o
sudo systemctl reload nginx
```

Certifique-se de que seu DNS (`A` ou `AAAA`) aponta `gurugpt.com.br` para o IP do servidor.

### 4. HTTPS com Certbot (opcional, recomendado)

```bash
sudo apt install certbot python3-certbot-nginx
sudo certbot --nginx -d gurugpt.com.br -d www.gurugpt.com.br
```

Isso irÃ¡:

- Gerar certificados TLS.
- Configurar redirecionamento HTTP â†’ HTTPS automaticamente.

---

## ğŸ§ª Uso bÃ¡sico

1. Acesse o endereÃ§o do app (local ou domÃ­nio).
2. Escolha um modelo Ollama na sidebar.
3. Envie mensagens no chat.
4. (Opcional) FaÃ§a upload de um PDF para que o modelo use o conteÃºdo como contexto.
5. Crie novas conversas pela sidebar para separar assuntos.

---

## ğŸ› ï¸ Roadmap / Ideias futuras

- ğŸ“š Suporte a mÃºltiplos arquivos e tipos (DOCX, TXT etc.).
- ğŸ’¾ PersistÃªncia de histÃ³rico em banco (SQLite/Postgres).
- ğŸ‘¤ AutenticaÃ§Ã£o de usuÃ¡rios.
- ğŸŒ SeleÃ§Ã£o de modelo remoto (APIs externas).

---

## ğŸ¤ ContribuiÃ§Ãµes

Pull requests, issues e sugestÃµes sÃ£o bem-vindas!
Sinta-se Ã  vontade para abrir uma issue com ideias de melhoria ou bugs encontrados.

---
## ğŸ“œ LicenÃ§a

GPL-3.0 license
